{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To get user picture for training"
      ],
      "metadata": {
        "id": "uZgTayGoTatb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "haar = 'haarcascade_frontalface_default.xml'\n",
        "ds = 'datasets'\n",
        "sd = 'champ'\n",
        "path = os.path.join(ds, sd)\n",
        "\n",
        "if not os.path.exists('C:\\getpic'):\n",
        "    os.makedirs('C:\\getpic')\n",
        "\n",
        "(width, height) = (130, 100)\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + haar)  # Load Haar cascade classifier\n",
        "cam = cv2.VideoCapture(0)\n",
        "count = 1\n",
        "\n",
        "while count <= 30:\n",
        "    print(count)\n",
        "    ret, im = cam.read()\n",
        "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "        face = gray[y:y + h, x:x + w]\n",
        "        face_resize = cv2.resize(face, (width, height))\n",
        "        cv2.imwrite(os.path.join('C:\\\\getpic', f'{count}.png'), face_resize)\n",
        "        count += 1\n",
        "\n",
        "    cv2.imshow('opencv', im)\n",
        "    key = cv2.waitKey(10)\n",
        "    if key == 27:\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "qUWVT-DvphIA",
        "outputId": "37bd4163-ae42-4df3-d5d1-5068bfeca5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4e27039f9e7f>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaleFactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recognising the face"
      ],
      "metadata": {
        "id": "myhvTuLzTgyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Loading Haar Cascade for face detection\n",
        "haar_cascade_file = 'haarcascade_frontalface_default.xml'\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + haar_cascade_file)\n",
        "\n",
        "dataset_path = 'datasets'\n",
        "\n",
        "print(\"Training...\")\n",
        "\n",
        "(images, labels, names, id) = ([], [], {}, 0)\n",
        "\n",
        "for (subdirs, dirs, files) in os.walk('C:\\\\getpic'):\n",
        "    for subdir in dirs:\n",
        "        names[id] = subdir\n",
        "        subject_path = os.path.join('C:\\\\getpic', subdir)\n",
        "\n",
        "        for filename in os.listdir(subject_path):\n",
        "            label = id\n",
        "            path = os.path.join(subject_path, filename)\n",
        "            images.append(cv2.imread(path, 0))\n",
        "            labels.append(int(label))\n",
        "        id += 1\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "(width, height) = (130, 100)\n",
        "\n",
        "# Create the LBPH face recognizer\n",
        "model = cv2.face_LBPHFaceRecognizer.create()\n",
        "\n",
        "model.train(images, labels)\n",
        "\n",
        "cam = cv2.VideoCapture(0)\n",
        "cnt = 0\n",
        "\n",
        "while True:\n",
        "    ret, im = cam.read()\n",
        "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(im, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
        "        face = gray[y:y + h, x:x + w]\n",
        "        face_resize = cv2.resize(face, (width, height))\n",
        "        prediction = model.predict(face_resize)\n",
        "        cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
        "        if prediction[1] < 95:\n",
        "            cv2.putText(im, f'{names[prediction[0]]}-{prediction[1]:.2f}', (x - 10, y - 10), cv2.FONT_HERSHEY_PLAIN, 2,\n",
        "                        (0, 0, 255))\n",
        "            print(names[prediction[0]])\n",
        "            cnt = 0\n",
        "        else:\n",
        "            cnt += 1\n",
        "            cv2.putText(im, 'unknown', (x + 10, y + 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0))\n",
        "            if cnt > 100:\n",
        "                print(\"unknown person\")\n",
        "                cv2.imwrite(\"unknown.jpg\", im)\n",
        "                cnt = 0\n",
        "\n",
        "    cv2.imshow('facerecognition', im)\n",
        "    key = cv2.waitKey(10)\n",
        "    if key == 27:\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "Prrw5Nblpkb0",
        "outputId": "5c1a9b83-c156-453e-c744-6b949e94b9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv_contrib/modules/face/src/lbph_faces.cpp:362: error: (-210:Unsupported format or combination of formats) Empty training data was given. You'll need more than one sample to learn a model. in function 'train'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f27a667f654e>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_LBPHFaceRecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv_contrib/modules/face/src/lbph_faces.cpp:362: error: (-210:Unsupported format or combination of formats) Empty training data was given. You'll need more than one sample to learn a model. in function 'train'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/sa02pJIxQSnZ0ygCLtfH"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}